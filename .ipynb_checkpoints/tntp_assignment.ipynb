{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "delayed-feature",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ProfileReport' from 'pandas_profiling' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cd86860fdc8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ProfileReport' from 'pandas_profiling' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Lets start with some common imports \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in our current working directory and list files\n",
    "\n",
    "ls = os.listdir()\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-implementation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Start by examining our educator effectiveness sheet\n",
    "\n",
    "effectiveness = pd.read_excel('EducatorEffectivenessSnapshot.csv.xlsx')\n",
    "effectiveness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-sword",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There are some details and text above our data \n",
    "# Lets break these up and fix our columns\n",
    "\n",
    "ef_header = effectiveness[:8]\n",
    "cols = effectiveness.iloc[5].to_list()\n",
    "effectiveness.columns = cols\n",
    "effectiveness = effectiveness[8:]\n",
    "effectiveness.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-application",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(effectiveness.info())\n",
    "print(effectiveness.describe())\n",
    "print(f'\\nThe shape is {effectiveness.shape}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found another row with no data and dropped it\n",
    "\n",
    "effectiveness.isnull().sum()\n",
    "effectiveness.loc[effectiveness['school_year'].isnull() == True]\n",
    "effectiveness.drop([113], inplace=True)\n",
    "effectiveness.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look at the distribution of our columns \n",
    "# The vast majority are highly efective\n",
    "\n",
    "ef_hist = effectiveness.drop(['location', 'school_year'], axis=1)\n",
    "ef_hist.plot(subplots=True, kind='hist', figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new df that contains just the columns we need\n",
    "\n",
    "\n",
    "freqcols = effectiveness[['highly_effective', 'effective', 'minimally_effective', \n",
    "            'ineffective']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-bracelet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Per business rule getting rid of the values < 10\n",
    "# Clip the lower bound and replace with NaN\n",
    "# Add the school location back in\n",
    "\n",
    "ef_clipped = freqcols.clip(9)\n",
    "\n",
    "ef_clean = ef_clipped.replace(9,np.NaN)\n",
    "ef_clean['location'] = effectiveness['location']\n",
    "\n",
    "ef_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-service",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading in the student scores sheet and taking a peek\n",
    "\n",
    "scores = pd.read_excel('StudentScores.csv.xlsx')\n",
    "print(scores.columns)\n",
    "scores.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-tender",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop unneeded cols\n",
    "scores = scores.drop(['school_year', 'ISDcode', 'ISDname', 'district_name', 'building_code', 'district_code'], axis = 1)\n",
    "\n",
    "# Break up the agg data and the student scores to another df\n",
    "all_buildings = scores.loc[scores['building_name'] == 'All Buildings']\n",
    "clean_scores = scores.iloc[len(all_buildings):]\n",
    "\n",
    "# Fixing location column name so we can merge our frames\n",
    "clean_scores = clean_scores.rename(columns = {'building_name': 'location'})\n",
    "\n",
    "# Making the full df from both sheets - mergin on location column\n",
    "mdf = pd.merge(ef_clean, clean_scores, on='location')\n",
    "\n",
    "# Some row data that is not numerical \n",
    "# Replace less than string in columns with NaN\n",
    "mdf = mdf.replace('< 10', np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-choir",
   "metadata": {},
   "source": [
    "### Populate a table showing the top ten schools in math proficiency along with their proficiency rates (percent of students scoring at proficient or higher). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-brand",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creatign a new df for all math related data \n",
    "\n",
    "math = mdf.loc[(mdf['subject_name'] == 'Mathematics') & (mdf['subgroup'] == 'All Students')]\n",
    "\n",
    "# Grouping by each school and only using the rows containing all students\n",
    "\n",
    "math10 = math.groupby(['location'])['percent_proficient'].mean().sort_values(ascending=False).head(10)\n",
    "\n",
    "\n",
    "print('Top 10 Schools in Math Proficient ')\n",
    "pd.DataFrame(round(math10.multiply(100))).reset_index()\n",
    "\n",
    "# Top 10 schools in proficiency of math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-hudson",
   "metadata": {},
   "source": [
    "### Your client for this project is the district’s Director of School Improvement. She asks your manager, a TNTP Project Director, if there is a relationship between the math proficiency of a school’s students and the effectiveness of its teachers. Draft a brief email message to your manager that answers this question, including an explanation of your analysis method(s) and what conclusion, if any, the district can draw from this analysis. Your manager does not have extensive data analysis experience. Your message should give your manager the information she needs to field this question from the client. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-coach",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab our freqcols from the new df (for clarity). No need for other cols right now\n",
    "# Making new df that ranks teachers effectiveness and plotting them together\n",
    "\n",
    "ef_cols = ['highly_effective', 'effective', 'minimally_effective', 'ineffective', 'location']\n",
    "teach_eff = mdf[ef_cols]\n",
    "teach_eff.plot(kind='hist', figsize=(12,8))\n",
    "\n",
    "# Adding in the proficiency \n",
    "teach_eff['percent_proficient'] = mdf['percent_proficient']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-access",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teach_eff.sort_values(by='percent_proficient', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "teach_eff.sort_values(by='percent_proficient', ascending=True).tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-midnight",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot a correlation matrix to examine any possible relationships between effectiveness and math scores\n",
    "\n",
    "corr = teach_eff.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-champagne",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = all_buildings.loc[(all_buildings['subgroup'] == 'All Students') & (all_buildings['subject_name'] == 'Mathematics')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a report just for our teacher effectiveness and proficiency \n",
    "pr = ProfileReport(teach_eff) \n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a report as if we did not remove <10 values -- just to see\n",
    "\n",
    "ef_no_removed = freqcols\n",
    "ef_no_removed['location'] = effectiveness['location']\n",
    "peek = pd.merge(ef_no_removed, clean_scores, on='location')\n",
    "peek = peek[['highly_effective', 'effective', 'minimally_effective', 'ineffective', 'percent_proficient']]\n",
    "\n",
    "ProfileReport(peek) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-addition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "data_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
