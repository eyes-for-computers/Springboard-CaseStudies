{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "precise-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging columns in many excel files to a standar format\n",
    "\n",
    "# Many staff have created their own excel sheets to show similiar\n",
    "# information. This script will find the standar name targets in\n",
    "# each sheet and put them into a single standard format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import Levenshtein\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas_profiling\n",
    "from pandas_profiling.utils.cache import cache_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broadband-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in all excel files in a folder and creates a single dataframe\n",
    "# Output is the full df and the column names that have been extracted\n",
    "\n",
    "def read_all_excel_cwd():\n",
    "\n",
    "    extracted_df = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "    x=0\n",
    "    test = pd.concat([extracted_df, test])\n",
    "\n",
    "    path = os.getcwd()\n",
    "    excel_files = glob.glob(os.path.join(path, \"*.xlsx\"))\n",
    "    print(excel_files)\n",
    "    \n",
    "    for file in excel_files:\n",
    "        print(len(excel_files))\n",
    "        x += 1\n",
    "        print('finished ', x, ' files')\n",
    "        df = pd.concat(pd.read_excel(file, sheet_name=None), ignore_index=True)\n",
    "        print(df.keys())\n",
    "        extracted_df = extracted_df.append(df)\n",
    "\n",
    "    extracted_df.columns = map(str.lower, extracted_df.columns[~'Date'])\n",
    "    extracted_cols = extracted_df.columns \n",
    "    extracted_df = extracted_df.set_index('date')\n",
    "    \n",
    "    print('should be df next')\n",
    "      \n",
    "    return extracted_df, extracted_cols\n",
    "\n",
    "# An extention on this would have it read in each file one by one to a dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "finite-admission",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#extracted_df, extracted_cols = read_all_excel_cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "relevant-clothing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#extracted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "analyzed-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of target behaviors that are being searched for\n",
    "\n",
    "bx_list = ['aggression', 'elope', 'non-compliance', 'sib', 'protesting'  ] #'agg','repeated' #'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-proposition",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function takes in the target bx list and the column names that have been extracted\n",
    "# and returns  match_df of the target bx, the matched column from the extracted_df and\n",
    "# the fuzz.partial_ratio of the match\n",
    "\n",
    "def fuzz_match(bx_list,extracted_cols):\n",
    "\n",
    "    matches = []\n",
    "    match_df = pd.DataFrame()\n",
    "\n",
    "    \n",
    "    for bx in bx_list:\n",
    "        print('working on: ', bx)\n",
    "    \n",
    "        for item in extracted_cols:\n",
    "           \n",
    "            fuzz_pr = fuzz.partial_ratio(item, bx)\n",
    "        \n",
    "            df_res = pd.DataFrame(data={'bx': bx, 'original_col_name' : item, 'fuzz_pr':fuzz_pr}, index=[i for i in range(len(extracted_df))] )\n",
    "            match_df = match_df.append(df_res)\n",
    "\n",
    "    return match_df\n",
    "\n",
    "#match_df = fuzz_match(bx_list,extracted_cols)\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df for each target bx match against the extracted_cols and joins them together in all_matches\n",
    "\n",
    "'''\n",
    "agg_matches = match_df.loc[(match_df.bx.str.contains('aggression')) & (match_df.fuzz_pr > 80)].drop_duplicates(subset =\"original_col_name\", keep ='first', inplace = False)\n",
    "\n",
    "elope_matches = match_df.loc[(match_df.bx.str.contains('elope')) & (match_df.fuzz_pr > 65)].drop_duplicates(subset =\"original_col_name\", keep ='first', inplace = False)\n",
    "\n",
    "noncomp_matches = match_df.loc[(match_df.bx.str.contains('non-compliance')) & (match_df.fuzz_pr > 90)].drop_duplicates(subset =\"original_col_name\", keep ='first', inplace = False)\n",
    "\n",
    "protest_matches = match_df.loc[(match_df.bx.str.contains('protest')) & (match_df.fuzz_pr > 70)].drop_duplicates(subset =\"original_col_name\", keep ='first', inplace = False)\n",
    "\n",
    "sib_matches = match_df.loc[(match_df.bx.str.contains('sib')) & (match_df.fuzz_pr > 80)].drop_duplicates(subset =\"original_col_name\", keep ='first', inplace = False)\n",
    "\n",
    "#date_matches = match_df.loc[(match_df.bx.str.contains('date')) & (match_df.fuzz_pr > 85)].drop_duplicates(subset =\"original_col_name\", keep ='first', inplace = False)\n",
    "\n",
    "\n",
    "all_matches = pd.concat([agg_matches, elope_matches, noncomp_matches, protest_matches, sib_matches])\n",
    "\n",
    "'''\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function takes in df of all matching bx and column names and returns the master_df\n",
    "# containing of the extracted columns data put into the target column names \n",
    "\n",
    "\n",
    "#make dictionary using extracted_df[old col name].to_dict()\n",
    "def add_to_master_df(all_matches):\n",
    "    \n",
    "    master_df = pd.DataFrame()\n",
    "    \n",
    "    master_df = extracted_df[all_matches['original_col_name'].tolist()]\n",
    "    master_df.columns = all_matches.bx.tolist()\n",
    "    master_df.head()\n",
    "    \n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = add_to_master_df(all_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-stevens",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "master_df.to_excel('master_df.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "data_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
