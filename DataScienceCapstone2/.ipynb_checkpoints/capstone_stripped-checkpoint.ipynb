{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "offshore-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fuzzywuzzy import process\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import Levenshtein\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas_profiling\n",
    "from pandas_profiling.utils.cache import cache_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broadband-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_excel_cwd():\n",
    "    \n",
    "    # Might need to try and str.lower() columns before indexing by date\n",
    "    # extracted_cols = list(df1['Behaviors'].keys())\n",
    "    # also need to deal with getting behaviors sheets\n",
    "#    df = pd.concat(pd.read_excel('2018_Sales_Total.xlsx', sheet_name=None), ignore_index=True)\n",
    "    extracted_df = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "    x=0\n",
    "    test = pd.concat([extracted_df, test])\n",
    "\n",
    "    path = os.getcwd()\n",
    "    excel_files = glob.glob(os.path.join(path, \"*.xlsx\"))\n",
    "    print(excel_files)\n",
    "    \n",
    "    for file in excel_files:\n",
    "        print(len(excel_files))\n",
    "        x += 1\n",
    "        print('finished ', x, ' files')\n",
    "        df = pd.concat(pd.read_excel(file, sheet_name=None), ignore_index=True)\n",
    "        print(df.keys())\n",
    "        extracted_df = extracted_df.append(df)\n",
    "\n",
    "#    extracted_df = df\n",
    "    extracted_df.columns = map(str.lower, extracted_df.columns)\n",
    "    extracted_cols = extracted_df.columns #still need to return this later\n",
    "    \n",
    "    print('should be df next')\n",
    "#    print(extracted_df)\n",
    "#    print(extracted_df)        \n",
    "    return extracted_df, extracted_cols\n",
    "\n",
    "#        df.columns = map(str.lower, df.columns)  \n",
    "#        print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "finite-admission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/eyesforcomputers/Scripts/git/DataScienceCapstone2/WQ_Graphs.xlsx', '/home/eyesforcomputers/Scripts/git/DataScienceCapstone2/FHA_BF90_RM_A_05312021.xlsx', '/home/eyesforcomputers/Scripts/git/DataScienceCapstone2/GO.xlsx']\n",
      "3\n",
      "finished  1  files\n",
      "Index(['Date', 'Elopement', 'Eloping', 'Self-Injurous Behavior', 'Eloped',\n",
      "       'Dropping', 'Agg ', 'Aggression', 'Non-Compliance', 'Mouthing',\n",
      "       'Protest', 'Non-comp', 'Agg', 'Crying',\n",
      "       'Off task during 1:1 with teacher', 'Accidents AM', 'Accidents PM',\n",
      "       'Phase Change', 'Unnamed: 4', 'Mands', 'Unnamed: 1', 'Target'],\n",
      "      dtype='object')\n",
      "3\n",
      "finished  2  files\n",
      "Index(['HUD PROJECT NUMBER', 'PROPERTY NAME', 'PROPERTY STREET',\n",
      "       'PROPERTY CITY', 'PROPERTY STATE', 'PROPERTY ZIP', 'UNITS',\n",
      "       'Unnamed: 7', 'Unnamed: 8', 'ORIGINAL MORTGAGE AMOUNT', 'Unnamed: 10',\n",
      "       'Unnamed: 11', 'TERM IN MONTHS', 'INTEREST RATE',\n",
      "       'CURRENT PRINCIPAL AND INTEREST', 'AMORITIZED PRINCIPAL BALANCE',\n",
      "       'HOLDER NAME', 'HOLDER CITY', 'HOLDER STATE', 'SERVICER NAME',\n",
      "       'SERVICER CITY', 'SERVICER STATE', 'SECTION OF ACT CODE',\n",
      "       'SOA CATEGORY/SUB CATEGORY', 'Unnamed: 24', 'Unnamed: 25'],\n",
      "      dtype='object')\n",
      "3\n",
      "finished  3  files\n",
      "Index(['Date', 'Aggression', 'Mouthing', 'Self-Talk', 'Repetitive Behaviors',\n",
      "       'Screaming', 'Date.1', 'Screaming.1', 'Non-Compliance', 'Self-Injury',\n",
      "       'Tantrum', 'Repeated Requests', 'Elopement', 'SSB', 'Legibly', 'When',\n",
      "       'RR-Personal Information', 'Good,Go,Do', 'And,What,Come',\n",
      "       'Rejection w/o problem behavior', 'Wait 5 minutes', '0 verbal prompts',\n",
      "       'Attend 5 mins', '2 exchanges with 1 prompt',\n",
      "       'Engage peer play 5 mins'],\n",
      "      dtype='object')\n",
      "should be df next\n"
     ]
    }
   ],
   "source": [
    "extracted_df, extracted_cols = read_all_excel_cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "analyzed-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_list = ['date','aggression', 'elope', 'non-compliance', 'sib', 'protesting', 'agg'  ] #'agg','repeated' #'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "listed-proposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on:  date\n",
      "working on:  aggression\n",
      "working on:  elope\n",
      "working on:  non-compliance\n",
      "working on:  sib\n",
      "working on:  protesting\n",
      "working on:  agg\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# need to add extracted_col in \n",
    "def fuzz_match():\n",
    "\n",
    "    matches = []\n",
    "    match_df = pd.DataFrame()\n",
    "    cols=['bx', 'original_col_name', 'fuzz_pr']\n",
    "\n",
    "    \n",
    "    for bx in bx_list:\n",
    "        print('working on: ', bx)\n",
    "    \n",
    "        for item in extracted_cols:\n",
    "           \n",
    "            fuzz_pr = fuzz.partial_ratio(item, bx)\n",
    "        \n",
    "            df_res = pd.DataFrame(data={'bx': bx, 'original_col_name' : item, 'fuzz_pr':fuzz_pr}, index=[i for i in range(len(extracted_df))] )\n",
    "            match_df = match_df.append(df_res)\n",
    "\n",
    "    return match_df\n",
    "\n",
    "match_df = fuzz_match()\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "piano-audience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Visually inspecting samples of the match_df by bx and fuzz_pr to determine a better match threshold\n",
    "#print('starting')\n",
    "# thresh = 80\n",
    "#date_matches_styled = match_df.loc[(match_df.bx.str.contains('date')) & (match_df.fuzz_pr > 50) & (match_df.fuzz_pr <= 100) ].groupby('fuzz_pr', sort=True).sample(10).style.background_gradient(subset='fuzz_pr',cmap='summer_r')\n",
    "\n",
    "#thresh 80\n",
    "#agg_matches_styled = match_df.loc[(match_df.bx.str.contains('aggression')) & (match_df.fuzz_pr > 50) & (match_df.fuzz_pr <= 100) ].groupby('fuzz_pr', sort=True).sample(10).style.background_gradient(subset='fuzz_pr',cmap='summer_r')\n",
    "\n",
    "#thresh 65\n",
    "#elope_matches_styled = match_df.loc[(match_df.bx.str.contains('elope')) & (match_df.fuzz_pr > 50) & (match_df.fuzz_pr <= 100) ].groupby('fuzz_pr', sort=True).sample(10).style.background_gradient(subset='fuzz_pr',cmap='summer_r')\n",
    "\n",
    "#thresh 90\n",
    "#noncomp_matches_styled = match_df.loc[(match_df.bx.str.contains('nc')) & (match_df.fuzz_pr > 50) & (match_df.fuzz_pr <= 100) ].groupby('fuzz_pr', sort=True).sample(10).style.background_gradient(subset='fuzz_pr',cmap='summer_r')\n",
    "\n",
    "# thresh=70\n",
    "#sib_matches_styled = match_df.loc[(match_df.bx.str.contains('sib')) & (match_df.fuzz_pr > 50) & (match_df.fuzz_pr <= 100) ].groupby('fuzz_pr', sort=True).sample(10).style.background_gradient(subset='fuzz_pr',cmap='summer_r')\n",
    "\n",
    "#print('done')\n",
    "\n",
    "#put the thresholds in a dictionary to access later\n",
    "fuzz_thresh = { 'agg_matches' : 70, 'elope_matches': 65, 'noncomp_matches' : 90} #'date_matches' : 80,\n",
    "\n",
    "\n",
    "#profile_report = match_df.profile_report(explorative=True, html={'style': {'full_width': True}})\n",
    "#profile_report\n",
    "\n",
    "\n",
    "\n",
    "agg_matches = match_df.loc[(match_df.bx.str.contains('aggression')) & (match_df.fuzz_pr > 80)].drop_duplicates(subset =\"original_col_name\", keep ='first', inplace = False)\n",
    "\n",
    "elope_matches = match_df.loc[(match_df.bx.str.contains('elope')) & (match_df.fuzz_pr > 65)].drop_duplicates(subset =\"original_col_name\", keep ='first', inplace = False)\n",
    "\n",
    "noncomp_matches = match_df.loc[(match_df.bx.str.contains('non-compliance')) & (match_df.fuzz_pr > 90)].drop_duplicates(subset =\"original_col_name\", keep ='first', inplace = False)\n",
    "\n",
    "date_matches = match_df.loc[(match_df.bx.str.contains('date')) & (match_df.fuzz_pr > 80)].drop_duplicates(subset =\"original_col_name\", keep ='first', inplace = False)\n",
    "\n",
    "all_matches = pd.concat([agg_matches,elope_matches,noncomp_matches,date_matches])\n",
    "\n",
    "print('done')\n",
    "\n",
    "#sib_matches = match_df.loc[(match_df.bx.str.contains('sib')) & (match_df.fuzz_pr > 70)].drop_duplicates(subset =\"original_col_name\", keep ='first', inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "helpful-reporter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bx</th>\n",
       "      <th>original_col_name</th>\n",
       "      <th>fuzz_pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aggression</td>\n",
       "      <td>aggression</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aggression</td>\n",
       "      <td>agg</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elope</td>\n",
       "      <td>elopement</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elope</td>\n",
       "      <td>eloping</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elope</td>\n",
       "      <td>eloped</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-compliance</td>\n",
       "      <td>non-compliance</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-compliance</td>\n",
       "      <td>non-comp</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>date</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>date.1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bx original_col_name  fuzz_pr\n",
       "0      aggression        aggression      100\n",
       "0      aggression               agg      100\n",
       "0           elope         elopement      100\n",
       "0           elope           eloping       80\n",
       "0           elope            eloped      100\n",
       "0  non-compliance    non-compliance      100\n",
       "0  non-compliance          non-comp      100\n",
       "0            date              date      100\n",
       "0            date            date.1      100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alleged-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_matches_styled = match_df.loc[(match_df.bx.str.contains('aggression')) & (match_df.fuzz_pr > 50) & (match_df.fuzz_pr <= 100) ].groupby('fuzz_pr', sort=True).sample(10).style.background_gradient(subset='fuzz_pr',cmap='summer_r')\n",
    "#agg_matches_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "three-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "charged-protocol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aggression'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_matches.bx)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bibliographic-knife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original_col_data = extracted_df.columns\n",
    "extracted_df['eloping'].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "proper-copying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggression  -  aggression\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0c07f4925169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0madd_to_master_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_matches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#    for item in matches:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-0c07f4925169>\u001b[0m in \u001b[0;36madd_to_master_df\u001b[0;34m(all_matches)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mproper_col_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mmaster_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproper_col_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_col_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#master_df[proper_col_name].append(original_col_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   7958\u001b[0m                 \u001b[0mcombined_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7959\u001b[0m             other = (\n\u001b[0;32m-> 7960\u001b[0;31m                 \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7961\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7962\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m   4343\u001b[0m     )\n\u001b[1;32m   4344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4347\u001b[0m     def drop(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4810\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4811\u001b[0;31m         return self._reindex_axes(\n\u001b[0m\u001b[1;32m   4812\u001b[0m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4813\u001b[0m         ).__finalize__(self, method=\"reindex\")\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   4830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4831\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4832\u001b[0;31m             obj = obj._reindex_with_indexers(\n\u001b[0m\u001b[1;32m   4833\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4834\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4876\u001b[0m             \u001b[0;31m# TODO: speed up on homogeneous DataFrame objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4877\u001b[0;31m             new_data = new_data.reindex_indexer(\n\u001b[0m\u001b[1;32m   4878\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4879\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   3474\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3476\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "# def add_to_master_df(all_matches):\n",
    "\n",
    "def add_to_master_df(all_matches):\n",
    "        \n",
    "        \n",
    "    for i, v in zip(all_matches.bx,all_matches.original_col_name):\n",
    "        print(i,' - ', v)\n",
    "        \n",
    "        original_col_data = extracted_df[v]\n",
    "        \n",
    "        proper_col_name = i\n",
    "            \n",
    "        master_df[proper_col_name] = master_df.append(original_col_data) #master_df[proper_col_name].append(original_col_data)\n",
    "                \n",
    "        \n",
    "#        print(i, v)\n",
    "        \n",
    "        \n",
    "\n",
    "add_to_master_df(all_matches)\n",
    "\n",
    "\n",
    "\n",
    "#WINNER\n",
    "#    master_df = extracted_df[all_matches['original_col_name'].tolist()]\n",
    "#    master_df.columns = all_matches.bx.tolist()\n",
    "#    master_df.head()\n",
    "\n",
    "\n",
    "\n",
    "#    for item in matches:\n",
    "        \n",
    "#    filter_bx = list(extracted_df.columns.str.contains(item[0]))\n",
    "#    proper_col_name = extracted_df.columns[filter_bx][0] \n",
    "#        print(proper_col_name)#\n",
    "\n",
    "\n",
    "#        original_col_data = extracted_df[item[0]]\n",
    "#        proper_col_name = item[2]\n",
    "#        print(proper_col_name)\n",
    "#        master_df[proper_col_name] = original_col_data \n",
    "           \n",
    "\n",
    "            \n",
    "#    return master_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "announced-embassy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggression</th>\n",
       "      <th>elope</th>\n",
       "      <th>non-compliance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18475 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aggression  elope  non-compliance\n",
       "date                                         \n",
       "2021-04-01         NaN    NaN             NaN\n",
       "2021-04-02         NaN    NaN             NaN\n",
       "2021-04-05         NaN    NaN             NaN\n",
       "2021-04-06         NaN    NaN             NaN\n",
       "2021-04-07         NaN    NaN             NaN\n",
       "...                ...    ...             ...\n",
       "NaT                NaN    NaN             NaN\n",
       "NaT                NaN    NaN             NaN\n",
       "NaT                NaN    NaN             NaN\n",
       "NaT                NaN    NaN             NaN\n",
       "NaT                NaN    NaN             NaN\n",
       "\n",
       "[18475 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.set_index('date').sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "changing-omega",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#master_df.elope.dropna(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "vital-graphics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aggression        295.0\n",
       "elope             240.0\n",
       "non-compliance     61.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.set_index('date').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-morning",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/string-matching-with-fuzzywuzzy-e982c61f8a84\n",
    "Need function to move through the bx_list and use process.extract on each.\n",
    "\n",
    "hmm that means that each iteration though the list it could find the same options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-colors",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "data_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
